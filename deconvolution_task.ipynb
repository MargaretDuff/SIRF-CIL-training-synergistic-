{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PET deconvolution Exercise\n",
    "\n",
    "1. Use STIR's `find_fwhm_in_image` utility to estimate the point spread function (PSF) using the point source measurement\n",
    "\n",
    "\n",
    "2. Use this PSF to deconvolve the OSEM reconstruction with the Richardson-Lucy (RL) algorithm\n",
    "\n",
    "3. RL can result in noise amplification. Use a CIL algorithm (we recommend PDHG) to do total variation (TV) regularised deconvolution\n",
    "\n",
    "\n",
    "4. Image guidance can improve the accuracy of reconstructions/deconvolutions. Use the T1 MRI image as guidance for deconvolution by implementing a directional TV. \n",
    "\n",
    "5. Proximal algorithms such as TV are used when our objective function in non-differentiable. TV (and it's directional counterpart) can be smoothed and then used with gradient-based algorithms. Implement a preconditioned gradient descent algorithm using directional TV as a prior. Does this improve the convergence properties? Does smoothing the prior effect the solution?\n",
    "\n",
    "6. What about when we have data from more than one modality? Can we use joint information to improve our resultant reconstructions? Implement a synergistic reconstruction and include Amyloid PET images in your deconvolution problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the libraries we need\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sirf.STIR as pet\n",
    "\n",
    "from cil.utilities.display import show2D\n",
    "from cil.optimisation.operators import  BlurringOperator\n",
    "\n",
    "import cil.optimisation.operators as op\n",
    "import cil.optimisation.algorithms as alg\n",
    "import cil.optimisation.functions as fn\n",
    "import cil.framework as cil\n",
    "\n",
    "msg = pet.MessageRedirector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global variables to ensure we are using the same data everytime\n",
    "\n",
    "noise_seed = 5\n",
    "bw_seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we'll define a few functions that we'll use later on\n",
    "# Some of these are redefined from the previous notebook and are included here for completeness\n",
    "# You'll also be able to find them in helper_functions.py if you want to use them in other notebooks or scripts\n",
    "# I haven't included any comments here as they can be found in helper_functions.py\n",
    "\n",
    "def make_acquisition_model(template_sinogram, template_image, atten_image):\n",
    "\n",
    "    acq_model = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    acq_model.set_num_tangential_LORs(10) \n",
    "    acq_asm = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    acq_asm.set_num_tangential_LORs(10)\n",
    "    acq_model.set_acquisition_sensitivity(pet.AcquisitionSensitivityModel(atten_image, acq_asm))\n",
    "    acq_model.set_up(template_sinogram,template_image)\n",
    "\n",
    "    return acq_model\n",
    "\n",
    "def find_fwhm_in_image(file_path):\n",
    "    \n",
    "    result = subprocess.run(['find_fwhm_in_image', file_path], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error running command:\", result.stderr)\n",
    "        return None\n",
    "    fwhm_regex = r\"The resolution in (.*) axis is ([\\d.]+)\"\n",
    "    matches = re.findall(fwhm_regex, result.stdout)\n",
    "    fwhm_values = {axis: float(value) for axis, value in matches}\n",
    "\n",
    "    return fwhm_values\n",
    "\n",
    "def fwhm_to_sigma(fwhm):\n",
    "    \n",
    "    return fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "\n",
    "def psf(n, fwhm, voxel_size=(1, 1, 1)):\n",
    "\n",
    "    sigma_voxels = [fwhm_to_sigma(fwhm[i]) / voxel_size[i] for i in range(3)]\n",
    "    axes = [np.linspace(-(n - 1) / 2., (n - 1) / 2., n) for i in range(3)]\n",
    "    gauss = [np.exp(-0.5 * np.square(ax) / np.square(sigma_voxels[i])) for i, ax in enumerate(axes)]\n",
    "    kernel_3d = np.outer(gauss[0], gauss[1]).reshape(n, n, 1) * gauss[2].reshape(1, 1, n)\n",
    "    return kernel_3d / np.sum(kernel_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the images we'll use in this notebook that we generated in the previous notebook\n",
    "\n",
    "image_list = ['PET', 'T1', 'uMap']\n",
    "image_dict = {}\n",
    "for image in image_list:\n",
    "    image_dict[image] = pet.ImageData(os.path.join('data', f'{image}_b{bw_seed}.hv'))\n",
    "image_dict['OSEM'] = pet.ImageData(os.path.join('data', f'OSEM_b{bw_seed}_n{noise_seed}.hv'))\n",
    "image_dict['OSEM_psf'] = pet.ImageData(os.path.join('data', f'OSEM_psf_n{noise_seed}.hv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now use a STIR utility to find the FWHM of the PSF in the point source reconstruction that we generated in the previous notebook\n",
    "\n",
    "fwhm = list(find_fwhm_in_image(os.path.join('data', f'OSEM_psf_n{noise_seed}.hv')).values())\n",
    "print(f'FWHM: {fwhm}')\n",
    "PSF=psf(5, fwhm=fwhm, voxel_size=image_dict['OSEM'].voxel_sizes())\n",
    "convolve=BlurringOperator(PSF, image_dict['PET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Richardson-Lucy algorithm\n",
    "\n",
    "If you understand MLEM, you understand RL. The RL update for image $u$ is:\n",
    "\n",
    "$$ x^{(n+1)} = x^{(n)} \\odot C^\\dagger \\ast \\frac{x_j^{(0)}}{C \\ast x^{(n)}} $$\n",
    "\n",
    "where we $C$ is our convolution kernel and $\\odot$, $\\ast$ denote the hadamard (element-wise) product and convolutional operators. We take a ratio of our OSEM image (which is our initial estimate) and our current estimate convolved with the point spread function that we estimated above. We then find the adjoint of this convolution and then multiply the result of this by the current image estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the above in code\n",
    "\n",
    "def RL(initial, convolution, iterations, eta=1e-6):\n",
    "    ''' Richardson-Lucy algorithm for deconvolution'''\n",
    "    \n",
    "    objective_values = [] # We'll store the objective values at each iteration here\n",
    "\n",
    "    current_estimate = initial.clone() # We'll update this estimate at each iteration\n",
    "    convolved_estimate = convolution.direct(current_estimate) # We'll store the convolved estimate here\n",
    "\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        current_estimate*= convolution.adjoint(initial/(convolved_estimate+eta)) # Our update is here\n",
    "        \n",
    "        convolved_estimate = convolution.direct(current_estimate) # update the convolved estimate\n",
    "        objective_values.append(convolved_estimate.sum() - (initial * (convolved_estimate+eta).log()).sum()) # calculate the objective value\n",
    "\n",
    "        print(f\"Iteration: {i}, Objective: {objective_values[-1]}\", end = '\\r')\n",
    "\n",
    "    return current_estimate, objective_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run this algorithm for 5, 20 and then 50 iterations to see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconvolved_5iter, obj_5iter = RL(image_dict['OSEM'], convolve, 5)\n",
    "\n",
    "show2D([deconvolved_5iter, image_dict['OSEM'], deconvolved_5iter-image_dict['PET']], \n",
    "       title = ['deconvolved image', 'OSEM image', 'difference to GT'], \n",
    "       origin = 'upper', num_cols = 3, fix_range=[(0,160), (0,160), (-40,40)],)\n",
    "\n",
    "plt.plot(obj_5iter)   \n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconvolved_20iter, obj_20iter = RL(image_dict['OSEM'], convolve, 20)\n",
    "\n",
    "show2D([deconvolved_20iter, image_dict['OSEM'], deconvolved_20iter-image_dict['PET']], \n",
    "       title = ['deconvolved image', 'OSEM image', 'difference to GT'], \n",
    "       origin = 'upper', num_cols = 3, fix_range=[(0,160), (0,160), (-40,40)],)\n",
    "\n",
    "plt.plot(obj_20iter)   \n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconvolved_50iter, obj_50iter = RL(image_dict['OSEM'], convolve, 50)\n",
    "\n",
    "show2D([deconvolved_50iter, image_dict['OSEM'], deconvolved_50iter-image_dict['PET']], \n",
    "       title = ['deconvolved image', 'OSEM image', 'difference to GT'], \n",
    "       origin = 'upper', num_cols = 3, fix_range=[(0,160), (0,160), (-40,40)],)\n",
    "\n",
    "plt.plot(obj_50iter)   \n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deconvolved_50iter.as_array()[4][50], label = 'RL-50 iterations')\n",
    "plt.plot(deconvolved_20iter.as_array()[4][50], label = 'RL-20 iterations')\n",
    "plt.plot(deconvolved_5iter.as_array()[4][50], label = 'RL-5 iterations')\n",
    "plt.plot(image_dict['OSEM'].as_array()[4][50], label = 'OSEM')\n",
    "plt.plot(image_dict['PET'].as_array()[4][50], label = 'Ground Truth')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Voxel Value')\n",
    "plt.title('Comparison of profiles at y=50')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF Modelling\n",
    "\n",
    "Estimating the PSF of our OSEM PET brain images from a point source OSEM reconstruction is not the most reliable way to estimate PSF and deconvolutions can be negatively effected by incorrerct PSF estimations (especially over estimations).\n",
    "\n",
    "This gives us an opportunity to do some investigations on this topic. Some questions:\n",
    "\n",
    "1. How does changing the PSF effect our deconvolved images (this can be done with RL or one of the algorithms with regularisation)\n",
    "2. Can you use SIRF/CIL to code a better way to estimate the PSF?\n",
    "\n",
    "If you'd like, spend some time on these questions here. If not, we'll move on to regularisation\n",
    "\n",
    "Some recommended papers are: \n",
    "\n",
    "On PSF estimation techniques:\n",
    "- [On the assessment of spatial resolution of PET systems with iterative image reconstruction](https://doi.org/10.1088/0031-9155/61/5/n193), Gong et al. \n",
    "- [Reducing between scanner differences in multi-center PET studies](https://doi.org/10.1016%2Fj.neuroimage.2009.01.057), Joshi et al.\n",
    "\n",
    "On the dangers of incorrect PSF estimation\n",
    "- [Resolution modeling in PET imaging: Theory, practice, benefits, and pitfalls](https://doi.org/10.1118/1.4800806), Rahmim et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved some reasonable image sharpening but can see that, even after only 50 iterations, we're starting to get a lot of noise amplification. Fortunately we know how to fix that... regularisation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularised Deconvolution\n",
    "\n",
    "In the second half of this notebook, we'll look at a few techniques to suppress the noise amplification that we have seen with RL.\n",
    "\n",
    "Firstly, we'll lay out a quick skeleton for a reconstruction using PDHG of total variation (TV) regularised deconvolution. If you need some help, there's a good example notebook [here](https://github.com/TomographicImaging/CIL-Demos/blob/main/demos/2_Iterative/03_PDHG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Variation regularised deconvolution\n",
    "\n",
    "For a deconvolution with PET (approximately Poisson noise) OSEM images, we construct a Bayesian log objective function:\n",
    "\n",
    "$$ \\Phi(\\mathbf{x}) = \\sum_j \\; \\Delta_{KL}((C \\ast x )_j;\\; \\bar{x}_{j}) + \\alpha \\Psi(x_j) $$\n",
    "\n",
    "where we have a data fidelity function $\\Delta_{KL}$ parameterised by our OSEM reconstruction $\\bar{x}$ and a regularisation function $\\Psi$. We sum up over all voxels $j$ to get our objective function value, which we want to minimise in this case. $\\alpha$ is a parameter to control the strength of regularisation. For Poisson noise, we need to use the negative Poisson log-likelihood. This is the same (to a constant) as the Kullback-Leibler divergence (KL), which is implemented in the Core Imaging Library (CIL) and with which SIRF's functionality has been designed.\n",
    "\n",
    "Total variation in as edge preserving prior orignally formulated [here](https://doi.org/10.1016/0167-2789(92)90242-F) for noise removal. There are a number of formulations but the one we'll use today is\n",
    "\n",
    "$$ \\Psi(x_j)_{TV} := |\\nabla x_j|_2$$\n",
    "\n",
    "Or the $l$-2 norm of the finite difference (we'll use the CIL default which is forward difference) operator, $\\nabla$ applied to our current image estimate. There is a wealth of literature on the TV prior for denoising, PET reconstruction and denoising so we won't got into any further detail here, but please do have a quick search on Scholar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDHG\n",
    "\n",
    "You don't need to understand this next part in order to complete the notebook but if you find it interesting, please do have a read:\n",
    "\n",
    "Total variation is non-smooth, which means that it is not continuously differentiable. Luckily for us, there are a class of algorithms known as proximal algorithms that can handle non-smooth functions. We can minimise our objective function by applying one or more proximal mappings, defined for a function $\\mathcal{F}$\n",
    "\n",
    "$$ \\text{prox}_{\\lambda \\mathcal{F}}(x) := \\underset{x^\\prime}{\\text{arg min }} \\mathcal{F}(x^\\prime) + \\frac{1}{2 \\lambda}|x - x^\\prime|_2^2 $$\n",
    "\n",
    "where $\\lambda$ controls the size of the step we take (akin to the step size in gradient descent). Unfortunately for us, neither the KL divergence when defined, as we have, with an operator nor TV have an explicit solution to the proximal mapping. Fortunately, their convex conjugates (also known as dual functions) do. We won't go into what a convex conjugate is here, but please see [here](https://remilepriol.github.io/dualityviz/) for what I think is a nice geometric visualisation of and [here](https://ocw.mit.edu/courses/6-253-convex-analysis-and-optimization-spring-2012/resources/mit6_253s12_lec01/) for some very good lecture notes on convex optimisation.\n",
    "\n",
    "The Primal-Dual Hybird Gradient algorithm (first published [here](https://link.springer.com/article/10.1007/s10851-010-0251-1)) uses this concept of duality (specifically strong duality) to optimise problems such as ours. We refer you again to [this](https://github.com/TomographicImaging/CIL-Demos/blob/main/demos/2_Iterative/03_PDHG.ipynb) notebook for a brief description of proximal operators and PDHG and how to use them in CIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK - let's set up a few bits and pieces for the optimisation problem\n",
    "\n",
    "alpha = 0.02 # This is by no means optimal, but it's a good starting point\n",
    "\n",
    "f1 = # We'll define the data fidelity term here\n",
    "f2 = alpha * # We'll define the regularisation term here\n",
    "\n",
    "f = fn.BlockFunction(f1, f2)\n",
    "\n",
    "g = fn.IndicatorBox(0) # This ensures non-negativity which is important for PET images\n",
    "\n",
    "grad = # We'll define the gradient operator here\n",
    "\n",
    "K = op.BlockOperator(convolve, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the step sizes for the primal and dual proximal mappings\n",
    "# These are by no means optimal, but they do guarantee convergence\n",
    "normK = K.norm()\n",
    "gamma = 1\n",
    "sigma = 0.99*gamma/normK\n",
    "tau = 0.99/(normK*gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This monkey patching is a temporary solution to a bug in CIL - possibly not needed in the future\n",
    "\n",
    "def update_previous_solution(self):\n",
    "    tmp = self.x_old\n",
    "    self.x_old = self.x\n",
    "    self.x = tmp\n",
    "\n",
    "alg.PDHG.update_previous_solution = update_previous_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg = # We'll define the PDHG algorithm here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg.run(verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/pdhg_setup.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look how we did...\n",
    "\n",
    "show2D([pdhg.solution, image_dict['OSEM'], pdhg.solution-image_dict['PET']],\n",
    "         title = ['deconvolved image', 'OSEM image', 'difference to GT'], \n",
    "         origin = 'upper', num_cols = 3, fix_range=[(0,160), (0,160), (-40,40)],)\n",
    "\n",
    "plt.plot(pdhg.objective)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image guidance\n",
    "\n",
    "OK, so this is all well and good but we have this beautiful MRI image just sitting there. How can we improve our reconstruction by utilising this high resolution image as guidance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the directional total variation regulariser\n",
    "\n",
    "$$\\Psi_{dTV}:= \\sum_j|D_i\\nabla x_j|_2$$\n",
    "\n",
    " where the sum is over the pixels $j$ and where $D$ is a weighting vector filed on the gradient in $x$ dependent on the normalised gradient, $\\zeta$,  of the reference image, $\\nu$ so \n",
    "$$D=I-\\zeta \\zeta^T$$\n",
    "and $$\\zeta = -\\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}}$$ where $0<\\eta<<\\|\\nabla\\nu\\|$.\n",
    "\n",
    "\n",
    "We can see that if $\\nabla x= \\gamma \\nabla \\nu$ then\n",
    "\n",
    " $$D\\nabla x = \\gamma D\\nabla \\nu= \\gamma (I-\\zeta \\zeta^T)\\nabla \\nu= \\gamma \\left(\\nabla \\nu -\\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\dfrac{\\nabla \\nu^T }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\nabla \\nu \\right)=\\gamma\\nabla \\nu \\left(1-(1+\\mathcal{O}(\\frac{\\eta^2}{\\|\\nabla\\nu\\|^2}) )\\right) \\approx 0.$$\n",
    "\n",
    "We can also see if the gradient of the reconstructed image and the reference image are perpendicular, $\\nabla x^T\\nabla \\nu=0$, then\n",
    "\n",
    "$$D\\nabla x (I-\\zeta \\zeta^T)\\nabla x= \\nabla \\nu - \\dfrac{\\nabla \\nu }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\dfrac{\\nabla \\nu^T }{\\sqrt{\\eta^2+|\\nabla\\nu|^2}} \\nabla x =\\nabla \\nu $$\n",
    "\n",
    " and is non-zero. \n",
    "\n",
    "This regulariser encourages the gradient of the reconstructed image to be equal to parallel to the gradient of the reference image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectionalOperator(op.LinearOperator):\n",
    "\n",
    "    def __init__(self, anatomical_gradient, gamma = 1, eta=1e-6):\n",
    "\n",
    "        self.anatomical_gradient = anatomical_gradient\n",
    "        geometry = cil.BlockGeometry(*[x for x in anatomical_gradient.containers])\n",
    "        self.tmp = self.anatomical_gradient.containers[0].clone()\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.xi = # We'll define the xi operator here\n",
    "\n",
    "        super(DirectionalOperator, self).__init__(domain_geometry=geometry,\n",
    "                                       range_geometry=geometry,)\n",
    "        \n",
    "    def direct(self, x, out=None):\n",
    "\n",
    "        # We'll define the direct operator here\n",
    "    \n",
    "    def adjoint(self, x, out=None):\n",
    "        \n",
    "        # We'll define the adjoint operator here\n",
    "    \n",
    "    def dot(self, x, y):\n",
    "        ''' This function calculates the elementwise dot product of two images'''\n",
    "        self.tmp.fill(0)\n",
    "        for el_x, el_y in zip(x.containers, y.containers):\n",
    "            self.tmp += el_x * el_y\n",
    "        return self.tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your operators and functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/DirectionalOperator.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normK = K.norm()\n",
    "gamma = 1\n",
    "sigma = gamma*0.99/normK\n",
    "tau = 0.99/(normK*gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhg_dtv = # We'll define the PDHG algorithm here\n",
    "\n",
    "pdhg_dtv.run(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/pdhg_dtv_setup.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look how we did...\n",
    "\n",
    "show2D([pdhg_dtv.solution, image_dict['OSEM'], pdhg_dtv.solution-image_dict['PET']],    \n",
    "         title = ['deconvolved image', 'OSEM image', 'difference to GT'], \n",
    "         origin = 'upper', num_cols = 3, fix_range=[(0,160), (0,160), (-40,40)],)\n",
    "\n",
    "\n",
    "plt.plot(pdhg_dtv.objective)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDHG means that we can optimise non-smooth problems but can be slow. There are many ways of improving this convergence speeds (stochastic subsets, hyperparameter optimisation, non-static step-sizes, strong convexity) but we'll go for a much easier solution here - we'll make the TV priors smooth. We can do this by adding a small parameter to ensure that there is no undefined gradient at $x=0$\n",
    "\n",
    "$$ \\Psi(x_j)_{TV} := |\\nabla x_j + \\eta^2|_2$$\n",
    "\n",
    "Now we can use gradient based algorithms. We'll let you use your imagination here. There are loads of algiorithms in CIL and many many more in literature. If you're struggling, there's an implementation of a preconditioned gradient descent algorithm in the solution notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/MAPRL.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/run_maprl.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on Regularised Deconvolution\n",
    "\n",
    "Some interesting questions that you could answer here are:\n",
    "\n",
    "1. How does the strength of the regulariser effect the deconvolved images?\n",
    "2. How does the amount of smoothing effect the deconvolved image and/or the convergence rate of our deconvolution algorithms\n",
    "3. Can you implement/use any other regularisation strategies (there are loads of options here. CIL has many to choose form or you can use the CIL framework to create one for yourself!)\n",
    "\n",
    "If you have anything else that you'd like to investigate, please fell free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergistic Deconvolution\n",
    "\n",
    "OK so we've used image guidance to improve our reconstructions but what about truly synergistic recosntructions with multiple modalities? First let's generate some different data. Run the cell below to generate and load some OSEM reconstructions of amyloid PET using the same patient but with different tracer dynamics and noise statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run python3 amyloid.py to generate an additional OSEM image\n",
    "\n",
    "subprocess.run(['python3', 'amyloid.py', f'--bw_seed={bw_seed}', f'--noise_seed={noise_seed+1}'])\n",
    "\n",
    "image_dict['OSEM_amyloid'] = pet.ImageData(os.path.join('data', f'OSEM_amyloid_b{bw_seed}_n{noise_seed+1}.hv'))\n",
    "image_dict['PET_amyloid'] = pet.ImageData(os.path.join('data', f'PET_amyloid_b{bw_seed}.hv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use what you've learned to do some Synergistic reconstructions. This will be a lot harder than the single-modality stuff that we've done so far. You'll need to read some of the CIL [documentation](https://tomographicimaging.github.io/CIL/nightly/) - especially the section on the block framework. Choose PDHG or something completely different! Again, there's a gradient-based solution in the solution notebook using smooth joint total variation but please only use this as a last resort. Ask us questions & get reading.\n",
    "\n",
    "You'll need a synergistic function as well as two separate data fidelity functions for the FDG PET and Amyloid PET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey patching TODO: remove in the future when CIL is updated\n",
    "# I found these changes to CIL to be useful for synergistic reconstruction but you may not. I'll leave them in here just in case\n",
    "\n",
    "def allocate(self, value=0):\n",
    "    ''' So we can create an empty BlockDataContainer '''\n",
    "    out = self.clone()\n",
    "    for el in out.containers:\n",
    "        el.fill(value)\n",
    "    return out\n",
    "\n",
    "cil.BlockDataContainer.allocate = allocate\n",
    "    \n",
    "def new(cls, *args, **kwargs):\n",
    "    ''' So that a shape=(1,1) BlockDataContainer is just a DataContainer'''\n",
    "    instance = super(cil.BlockDataContainer, cls).__new__(cls) \n",
    "    instance.__init__(*args, **kwargs)\n",
    "\n",
    "    if getattr(instance, 'shape', None) == (1, 1):\n",
    "        return cls.containers[0] \n",
    "    return instance\n",
    "\n",
    "cil.BlockDataContainer.__new__ = staticmethod(new)\n",
    "\n",
    "class bdc_FOV_filter(pet.TruncateToCylinderProcessor):\n",
    "    ''' \n",
    "    A class to apply the FOV filter to each element of a BlockDataContainer \n",
    "    An FOV filter is a cylindrical filter that removes data outside of the FOV\n",
    "    It's useful to remove edge effects in PET image\n",
    "    '''\n",
    "    def apply(self, bdc):\n",
    "        for el in bdc.containers:\n",
    "            super().apply(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And away we go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/MergeBlockDataContainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/run_synergistic_maprl.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/BlockIndicator.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load './snippets/run_spdhg.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
